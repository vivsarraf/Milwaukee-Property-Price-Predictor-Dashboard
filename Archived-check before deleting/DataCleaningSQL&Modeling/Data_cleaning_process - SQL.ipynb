{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Using SQL for Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries and Loading the CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T01:48:27.629796Z",
     "start_time": "2024-06-11T01:48:26.460723Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ebehnia\\AppData\\Local\\Temp\\ipykernel_17960\\1590189496.py:12: DtypeWarning: Columns (12,17,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'Resources/2013_to_2023_property-sales-data.csv'\n",
    "\n",
    "dtype_dict = {\n",
    "    'FinishedSqft': 'str',\n",
    "    'Lotsize': 'str',\n",
    "    'Sale_price': 'str'\n",
    "}\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing and Standardizing the Date Format in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T01:48:27.635791Z",
     "start_time": "2024-06-11T01:48:27.631480Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to parse and standardize the date format\n",
    "def parse_date(date_str):\n",
    "    for fmt in (\"%Y-%m-%d\", \"%m/%d/%Y\", \"%d-%b-%y\", \"%b-%y\"):\n",
    "        try:\n",
    "            return datetime.strptime(date_str, fmt).strftime(\"%Y-%m-%d\")\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "# Apply the function to the 'Sale_date' column\n",
    "data['Sale_date'] = data['Sale_date'].apply(parse_date)\n",
    "\n",
    "# Check for any dates that couldn't be parsed\n",
    "unparsed_dates = data[data['Sale_date'].isna()]\n",
    "unparsed_dates_count = len(unparsed_dates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Numeric Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean numeric columns\n",
    "def clean_numeric(column):\n",
    "    # Ensure the column is a string, replace unwanted characters, and convert to numeric\n",
    "    return pd.to_numeric(column.astype(str).str.replace('[\\\\$,]', '', regex=True).str.replace(',', ''), errors='coerce')\n",
    "\n",
    "# Cleaning and converting the 'FinishedSqft', 'Lotsize', and 'Sale_price' columns\n",
    "data['FinishedSqft'] = clean_numeric(data['FinishedSqft'])\n",
    "data['Lotsize'] = clean_numeric(data['Lotsize'])\n",
    "data['Sale_price'] = clean_numeric(data['Sale_price'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T01:48:27.887698Z",
     "start_time": "2024-06-11T01:48:27.637235Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data[data.PropType == 'Residential']\n",
    "data = data[data.Sale_price >= 50000]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Unnecessary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T01:48:27.911639Z",
     "start_time": "2024-06-11T01:48:27.890175Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dropping columns with unique values\n",
    "data = data.drop(columns=['PropertyID', 'taxkey', 'Address', 'CondoProject', 'PropType'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T01:48:27.920547Z",
     "start_time": "2024-06-11T01:48:27.913127Z"
    }
   },
   "outputs": [],
   "source": [
    "data['Stories'] = data['Stories'].fillna(1.0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert and Add Date Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T01:48:27.955457Z",
     "start_time": "2024-06-11T01:48:27.922033Z"
    }
   },
   "outputs": [],
   "source": [
    "# Converting 'Sale_date' to datetime with mixed format and adding sale-year and sale-month columns\n",
    "data['Sale_date'] = pd.to_datetime(data['Sale_date'], errors='coerce')\n",
    "data['sale_year'] = data['Sale_date'].dt.year\n",
    "data['sale_month'] = data['Sale_date'].dt.month\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T01:48:27.987462Z",
     "start_time": "2024-06-11T01:48:27.956704Z"
    }
   },
   "outputs": [],
   "source": [
    "# Standardize column names to lowercase\n",
    "data.columns = [col.lower() for col in data.columns]\n",
    "\n",
    "# Standardizing categorical columns to consistent capitalization\n",
    "data['style'] = data['style'].str.lower()\n",
    "data['extwall'] = data['extwall'].str.lower()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T01:48:28.012085Z",
     "start_time": "2024-06-11T01:48:27.988752Z"
    }
   },
   "outputs": [],
   "source": [
    "# For simplicity, we'll drop rows with missing target values (sale_price) and rows with excessive missing values.\n",
    "data_cleaned = data.dropna(subset=['sale_price', 'sale_date', 'finishedsqft', 'district', 'nbhd', 'lotsize', 'hbath', 'fbath', 'rooms', 'extwall'])\n",
    "\n",
    "# Removing Duplicate Records\n",
    "data_cleaned = data_cleaned.drop_duplicates()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for Null Values and Reset Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for null values\n",
    "null_rows = data_cleaned[data_cleaned.isnull().any(axis=1)]\n",
    "\n",
    "# Resetting the index\n",
    "data_cleaned = data_cleaned.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the cleaned data back to a CSV file\n",
    "cleaned_file_path = 'Resources/clean_property_data-sql2.csv'\n",
    "data_cleaned.to_csv(cleaned_file_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
